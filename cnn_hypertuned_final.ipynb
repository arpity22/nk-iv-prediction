{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ce8a7",
   "metadata": {
    "_cell_guid": "cb61d13a-4694-4e9d-8a04-abf8c9fd29fd",
    "_uuid": "982f8cd9-20d0-4c08-be27-627ad48b4177",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:03.639407Z",
     "iopub.status.busy": "2025-06-12T10:12:03.639156Z",
     "iopub.status.idle": "2025-06-12T10:12:13.793352Z",
     "shell.execute_reply": "2025-06-12T10:12:13.792235Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 10.160044,
     "end_time": "2025-06-12T10:12:13.794821",
     "exception": false,
     "start_time": "2025-06-12T10:12:03.634777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aad12af",
   "metadata": {
    "_cell_guid": "7aadc150-6c3e-4a91-9abf-e8d128e883f5",
    "_uuid": "72db2fe2-acfb-4168-b593-802286e09d1b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:13.803659Z",
     "iopub.status.busy": "2025-06-12T10:12:13.803238Z",
     "iopub.status.idle": "2025-06-12T10:12:13.807938Z",
     "shell.execute_reply": "2025-06-12T10:12:13.806995Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010839,
     "end_time": "2025-06-12T10:12:13.809534",
     "exception": false,
     "start_time": "2025-06-12T10:12:13.798695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_path = '/kaggle/input/nk-iv-prediction'\n",
    "output_path = '/kaggle/working'\n",
    "temp_path = '/kaggle/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3ed98b",
   "metadata": {
    "_cell_guid": "c07f558d-9e10-40e4-9d25-0f6c4070c0f8",
    "_uuid": "8f30204d-ac3a-44f0-956f-7c0650d22677",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:13.817968Z",
     "iopub.status.busy": "2025-06-12T10:12:13.817581Z",
     "iopub.status.idle": "2025-06-12T10:12:15.832335Z",
     "shell.execute_reply": "2025-06-12T10:12:15.831370Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.020931,
     "end_time": "2025-06-12T10:12:15.834095",
     "exception": false,
     "start_time": "2025-06-12T10:12:13.813164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_parquet(f'{data_path}/train_data.parquet')\n",
    "test_df = pd.read_parquet(f'{data_path}/test_data.parquet')\n",
    "sample_df = pd.read_csv(f'{data_path}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d1b9e0",
   "metadata": {
    "_cell_guid": "566a22b8-f799-48d5-a814-9fa60a6d8d46",
    "_uuid": "42413833-ec38-49ca-bedc-be26b996ac17",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:15.843123Z",
     "iopub.status.busy": "2025-06-12T10:12:15.842176Z",
     "iopub.status.idle": "2025-06-12T10:12:15.909545Z",
     "shell.execute_reply": "2025-06-12T10:12:15.908742Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.073407,
     "end_time": "2025-06-12T10:12:15.911188",
     "exception": false,
     "start_time": "2025-06-12T10:12:15.837781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "iv_cols = [col for col in sample_df.columns if col.startswith(\"call_iv_\") or col.startswith(\"put_iv_\")]\n",
    "\n",
    "# Normalize IV matrix\n",
    "data_matrix = test_df[iv_cols].copy()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_norm = scaler.fit_transform(data_matrix.fillna(0))\n",
    "mask = ~data_matrix.isna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb34f6",
   "metadata": {
    "_cell_guid": "8c246e4e-99de-4cc4-a9e7-6a09599cb0a8",
    "_uuid": "bf774fd5-4c01-441a-8e01-89034fac3953",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:15.919575Z",
     "iopub.status.busy": "2025-06-12T10:12:15.919292Z",
     "iopub.status.idle": "2025-06-12T10:12:15.924969Z",
     "shell.execute_reply": "2025-06-12T10:12:15.924358Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011394,
     "end_time": "2025-06-12T10:12:15.926288",
     "exception": false,
     "start_time": "2025-06-12T10:12:15.914894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset with masking noise\n",
    "class IVMatrixDataset(Dataset):\n",
    "    def __init__(self, data, mask):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx].clone()\n",
    "        m = self.mask[idx]\n",
    "        noise = (torch.rand_like(x) < 0.2) & m.bool()\n",
    "        x[noise] = 0\n",
    "        return x, self.data[idx], m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433e85e",
   "metadata": {
    "_cell_guid": "387a518c-3d47-4a4e-8c3f-1d6fdfb5b69d",
    "_uuid": "dc163a79-7d89-40ce-b2c0-0f7ec81353d1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:15.934940Z",
     "iopub.status.busy": "2025-06-12T10:12:15.934161Z",
     "iopub.status.idle": "2025-06-12T10:12:15.939932Z",
     "shell.execute_reply": "2025-06-12T10:12:15.939171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01164,
     "end_time": "2025-06-12T10:12:15.941507",
     "exception": false,
     "start_time": "2025-06-12T10:12:15.929867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define weighted MSE loss function\n",
    "def weighted_mse_loss(pred, target, mask):\n",
    "    # Create weights that emphasize at-the-money options\n",
    "    n_strikes = pred.shape[1] // 2  # Half for calls, half for puts\n",
    "    \n",
    "    # Create weights centered around ATM (middle strikes)\n",
    "    atm_idx = n_strikes // 2\n",
    "    strike_weights = 1.0 / (1.0 + 0.2 * torch.abs(torch.arange(n_strikes, device=pred.device) - atm_idx))\n",
    "    \n",
    "    # Duplicate weights for both calls and puts\n",
    "    weights = torch.cat([strike_weights, strike_weights], dim=0)\n",
    "    \n",
    "    # Apply weights to the squared error (only on known values)\n",
    "    squared_error = ((pred - target) * mask) ** 2\n",
    "    \n",
    "    # Apply strike weights to each column\n",
    "    weighted_error = squared_error * weights.view(1, -1)\n",
    "    \n",
    "    # Normalize by the sum of masks to get mean error only on observed values\n",
    "    return torch.sum(weighted_error) / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a92f0f",
   "metadata": {
    "_cell_guid": "8141253a-f008-4ebe-a6fb-770233bf820e",
    "_uuid": "dc64c4b1-14b7-4b39-ada8-b8f6d11290fb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:15.950315Z",
     "iopub.status.busy": "2025-06-12T10:12:15.949678Z",
     "iopub.status.idle": "2025-06-12T10:12:15.960313Z",
     "shell.execute_reply": "2025-06-12T10:12:15.959335Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016723,
     "end_time": "2025-06-12T10:12:15.961871",
     "exception": false,
     "start_time": "2025-06-12T10:12:15.945148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TunableCNN(nn.Module):\n",
    "    def __init__(self, n_features, config):\n",
    "        super().__init__()\n",
    "        # Split features into calls and puts\n",
    "        self.n_features = n_features\n",
    "        self.n_strikes = n_features // 2  # Assuming equal call/put count\n",
    "        \n",
    "        # Get hyperparameters from config\n",
    "        self.encoder_filters = config['encoder_filters']\n",
    "        self.kernel_size = config['kernel_size']\n",
    "        self.latent_dim = config['latent_dim']\n",
    "        self.dropout_rate = config['dropout_rate']\n",
    "        \n",
    "        # CNN Encoder layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=self.encoder_filters[0], \n",
    "                              kernel_size=self.kernel_size, padding=self.kernel_size//2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.encoder_filters[0], out_channels=self.encoder_filters[1], \n",
    "                              kernel_size=self.kernel_size, padding=self.kernel_size//2)\n",
    "        \n",
    "        # FC latent representation\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_latent = nn.Linear(self.encoder_filters[1] * self.n_strikes, self.latent_dim)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.fc_decode = nn.Linear(self.latent_dim, 64)\n",
    "        self.fc_reshape = nn.Linear(64, self.encoder_filters[0] * self.n_strikes)\n",
    "        self.conv3 = nn.Conv1d(in_channels=self.encoder_filters[0], out_channels=2, \n",
    "                              kernel_size=self.kernel_size, padding=self.kernel_size//2)\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Reshape to [batch, 2, strikes] - organizing calls and puts for CNN\n",
    "        x_reshaped = x.view(batch_size, 2, self.n_strikes)\n",
    "        \n",
    "        # Encoder\n",
    "        e1 = self.relu(self.conv1(x_reshaped))\n",
    "        e1 = self.dropout(e1)\n",
    "        e2 = self.relu(self.conv2(e1))\n",
    "        e2 = self.dropout(e2)\n",
    "        \n",
    "        # Flatten and get latent representation\n",
    "        flat = self.flatten(e2)\n",
    "        z = self.relu(self.fc_latent(flat))\n",
    "        \n",
    "        # Decoder\n",
    "        d1 = self.relu(self.fc_decode(z))\n",
    "        d2 = self.relu(self.fc_reshape(d1))\n",
    "        d2 = d2.view(batch_size, self.encoder_filters[0], self.n_strikes)\n",
    "        \n",
    "        d2 = d2 + e1\n",
    "        \n",
    "        # Final convolution to get output\n",
    "        out = self.sigmoid(self.conv3(d2))\n",
    "        \n",
    "        # Reshape back to original format\n",
    "        return out.view(batch_size, self.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34dede",
   "metadata": {
    "_cell_guid": "dc05d7c2-96d9-4583-999d-0569fe2a4cea",
    "_uuid": "d899f845-df38-4ed1-a01f-7a4707e40036",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:16.007385Z",
     "iopub.status.busy": "2025-06-12T10:12:16.007079Z",
     "iopub.status.idle": "2025-06-12T10:12:16.016663Z",
     "shell.execute_reply": "2025-06-12T10:12:16.015888Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015122,
     "end_time": "2025-06-12T10:12:16.017905",
     "exception": false,
     "start_time": "2025-06-12T10:12:16.002783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_optimized_model(data_norm, mask, best_params):\n",
    "    # Prepare config from best params\n",
    "    config = {\n",
    "        'encoder_filters': [\n",
    "            best_params['filters1'],\n",
    "            best_params['filters2']\n",
    "        ],\n",
    "        'kernel_size': best_params['kernel_size'],\n",
    "        'latent_dim': best_params['latent_dim'],\n",
    "        'dropout_rate': best_params['dropout_rate'],\n",
    "        'learning_rate': best_params['learning_rate'],\n",
    "        'batch_size': best_params['batch_size']\n",
    "    }\n",
    "    \n",
    "    print(f\"Training optimized model with config: {config}\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = IVMatrixDataset(data_norm, mask)\n",
    "    dataloader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TunableCNN(data_norm.shape[1], config).to(device)\n",
    "    # Use Adam optimizer with learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=100, \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Train the model with optimized hyperparameters (using same parameters as original training)\n",
    "    best_loss = float('inf')\n",
    "    patience = 200\n",
    "    patience_counter = 0\n",
    "    best_state_dict = None\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(3000):\n",
    "        total_loss = 0\n",
    "        for x_noisy, x_true, m in dataloader:\n",
    "            x_noisy = x_noisy.to(device)\n",
    "            x_true = x_true.to(device)\n",
    "            m = m.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x_noisy)\n",
    "            loss = weighted_mse_loss(pred, x_true, m)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss for this epoch\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        \n",
    "        # Update learning rate based on loss\n",
    "        prev_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(avg_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model weights\n",
    "            best_state_dict = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {avg_loss:.6f}, LR: {current_lr:.6e}\")\n",
    "    \n",
    "    # Load best model for return\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f7707",
   "metadata": {
    "_cell_guid": "6a2a939d-b222-4642-b94e-dcde7cd86e94",
    "_uuid": "990a9de9-0a41-4ea0-bf07-6cc0cf9d9ad0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-12T10:12:16.026223Z",
     "iopub.status.busy": "2025-06-12T10:12:16.025920Z",
     "iopub.status.idle": "2025-06-12T11:37:24.033938Z",
     "shell.execute_reply": "2025-06-12T11:37:24.032684Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5108.014072,
     "end_time": "2025-06-12T11:37:24.035589",
     "exception": false,
     "start_time": "2025-06-12T10:12:16.021517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Training optimized model with config: {'encoder_filters': [16, 48], 'kernel_size': 5, 'latent_dim': 56, 'dropout_rate': 0.0, 'learning_rate': 0.003519672678761618, 'batch_size': 64}\n",
      "Epoch 50, Loss: 0.000029, LR: 3.519673e-03\n",
      "Epoch 100, Loss: 0.000018, LR: 3.519673e-03\n",
      "Epoch 150, Loss: 0.000013, LR: 3.519673e-03\n",
      "Epoch 200, Loss: 0.000012, LR: 3.519673e-03\n",
      "Epoch 250, Loss: 0.000010, LR: 3.519673e-03\n",
      "Epoch 300, Loss: 0.000010, LR: 3.519673e-03\n",
      "Epoch 350, Loss: 0.000010, LR: 3.519673e-03\n",
      "Epoch 400, Loss: 0.000008, LR: 3.519673e-03\n",
      "Epoch 450, Loss: 0.000010, LR: 3.519673e-03\n",
      "Epoch 500, Loss: 0.000010, LR: 3.519673e-03\n",
      "Epoch 550, Loss: 0.000009, LR: 3.519673e-03\n",
      "Epoch 600, Loss: 0.000010, LR: 3.519673e-03\n",
      "Epoch 650, Loss: 0.000009, LR: 3.519673e-03\n",
      "Epoch 700, Loss: 0.000008, LR: 3.519673e-03\n",
      "Epoch 750, Loss: 0.000009, LR: 3.519673e-03\n",
      "Epoch 800, Loss: 0.000008, LR: 3.519673e-03\n",
      "Epoch 850, Loss: 0.000007, LR: 1.759836e-03\n",
      "Epoch 900, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 950, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1000, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1050, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1100, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1150, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1200, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1250, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1300, Loss: 0.000006, LR: 1.759836e-03\n",
      "Epoch 1350, Loss: 0.000005, LR: 8.799182e-04\n",
      "Epoch 1400, Loss: 0.000005, LR: 8.799182e-04\n",
      "Epoch 1450, Loss: 0.000005, LR: 8.799182e-04\n",
      "Epoch 1500, Loss: 0.000005, LR: 4.399591e-04\n",
      "Epoch 1550, Loss: 0.000005, LR: 4.399591e-04\n",
      "Epoch 1600, Loss: 0.000005, LR: 4.399591e-04\n",
      "Epoch 1650, Loss: 0.000005, LR: 4.399591e-04\n",
      "Epoch 1700, Loss: 0.000005, LR: 4.399591e-04\n",
      "Epoch 1750, Loss: 0.000004, LR: 2.199795e-04\n",
      "Epoch 1800, Loss: 0.000004, LR: 2.199795e-04\n",
      "Epoch 1850, Loss: 0.000004, LR: 1.099898e-04\n",
      "Epoch 1900, Loss: 0.000004, LR: 1.099898e-04\n",
      "Epoch 1950, Loss: 0.000004, LR: 1.099898e-04\n",
      "Epoch 2000, Loss: 0.000004, LR: 5.499489e-05\n",
      "Epoch 2050, Loss: 0.000004, LR: 5.499489e-05\n",
      "Epoch 2100, Loss: 0.000004, LR: 5.499489e-05\n",
      "Epoch 2150, Loss: 0.000004, LR: 2.749744e-05\n",
      "Epoch 2200, Loss: 0.000004, LR: 2.749744e-05\n",
      "Early stopping at epoch 2204\n",
      "Optimized model submission saved to optimized_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the best parameters from hyperparameter tuning\n",
    "# The best hyperparameters found via running the \"cnn_hypertuning.ipynb\" notebook\n",
    "best_params = {'filters1': 16, 'filters2': 48, 'kernel_size': 5, 'latent_dim': 56, 'dropout_rate': 0.0, 'learning_rate': 0.003519672678761618, 'batch_size': 64}\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "optimized_model = train_optimized_model(data_norm, mask, best_params)\n",
    "\n",
    "# Save the optimized model\n",
    "torch.save(optimized_model.state_dict(), \"optimized_cnn.pt\")\n",
    "\n",
    "# Generate predictions using the optimized model\n",
    "optimized_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Process in batches to prevent memory issues\n",
    "    batch_size = best_params['batch_size']\n",
    "    cnn_preds = np.zeros_like(data_norm)\n",
    "    \n",
    "    for i in range(0, data_norm.shape[0], batch_size):\n",
    "        end_idx = min(i + batch_size, data_norm.shape[0])\n",
    "        batch_data = torch.tensor(data_norm[i:end_idx], dtype=torch.float32).to(device)\n",
    "        preds = optimized_model(batch_data).cpu().numpy()\n",
    "        cnn_preds[i:end_idx] = preds\n",
    "    \n",
    "    # Save predictions\n",
    "    np.save('optimized_cnn_preds.npy', cnn_preds)\n",
    "    # Rescale predictions back to original scale\n",
    "    optimized_imputed_rescaled = scaler.inverse_transform(cnn_preds)\n",
    "\n",
    "# Create final submission DataFrame with optimized model results\n",
    "optimized_df = pd.DataFrame(optimized_imputed_rescaled, columns=iv_cols)\n",
    "optimized_df.insert(0, \"timestamp\", sample_df[\"timestamp\"])\n",
    "for col in iv_cols:\n",
    "    optimized_df[col] = np.clip(optimized_df[col], 0.01, 1.5)\n",
    "optimized_df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"Optimized model submission saved to submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b6eda",
   "metadata": {},
   "source": [
    "The model is prone to fluctuations due to early stopping and learning rate scheduler. On tests conducted after competition end, performance varies from MSE score of 0.000001965 to 0.000002155"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12520411,
     "sourceId": 104024,
     "sourceType": "competition"
    },
    {
     "datasetId": 7616602,
     "sourceId": 12098587,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5128.982385,
   "end_time": "2025-06-12T11:37:27.624549",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T10:11:58.642164",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
